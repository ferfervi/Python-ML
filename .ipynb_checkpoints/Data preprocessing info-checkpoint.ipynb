{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------------------------\n",
    "\n",
    "\n",
    "# DATA  PREPROCESSING\n",
    "- ### A) DEALING WITH NULL VALUES\n",
    "- ### B)CATEGORICAL DATA INTO SHAPE FOR ML \n",
    "- ### C)FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B   C   D\n",
       "0  1   2   3   4\n",
       "1  5   6 NaN   8\n",
       "2  0  11  12 NaN"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csv_data = '''A,B,C,D\n",
    "1.0,2.0,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "0.0,11.0,12.0,'''\n",
    "\n",
    "#in python 2.7 we need to transorm it to unicode\n",
    "csv_data = unicode(csv_data)\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Dealing with null values\n",
    "#### Removing rows / Columns that contain NaN, null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0\n",
       "B    0\n",
       "C    1\n",
       "D    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIRST INSPECTION: IF OUR DATAFRAME HAS NULL VALUES. DROP THEM\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  1  2  3  4"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One solution is to remove the rows (samples) or columns (features) that ontain null values\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B\n",
       "0  1   2\n",
       "1  5   6\n",
       "2  0  11"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set that we want to opperate with columns\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B   C  D\n",
       "0  1  2   3  4\n",
       "1  5  6 NaN  8"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing  NaN that are contained in a certain column. ex (D)\n",
    "df.dropna(subset= ['D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Remove the values is not always a possibility due that we may run out of data, other possibilities may be taken into consideration.\n",
    "\n",
    "#### Imputing missing values: replace missing values for values such as mean or median.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B     C  D\n",
       "0  1   2   3.0  4\n",
       "1  5   6   7.5  8\n",
       "2  0  11  12.0  6"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "#axis = 1 will calculate means by row\n",
    "imr = Imputer(missing_values ='NaN',strategy='mean', axis = 0)\n",
    "imr = imr.fit(df)\n",
    "imputed_data = imr.transform(df.values)\n",
    "#we get a list of arrays, rows... convert it to DF\n",
    "pd.DataFrame(imputed_data,columns=['A','B','C','D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Handling Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yellow</td>\n",
       "      <td>S</td>\n",
       "      <td>22.4</td>\n",
       "      <td>model1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purple</td>\n",
       "      <td>M</td>\n",
       "      <td>25.4</td>\n",
       "      <td>model1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pink</td>\n",
       "      <td>L</td>\n",
       "      <td>29.4</td>\n",
       "      <td>model2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    color size  price   model\n",
       "0  yellow    S   22.4  model1\n",
       "1  purple    M   25.4  model1\n",
       "2    pink    L   29.4  model2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([['yellow','S',22.4, 'model1'],\n",
    "                  ['purple','M',25.4, 'model1'],\n",
    "                  ['pink','L',29.4, 'model2']],columns =['color','size','price','model'])\n",
    "df\n",
    "\n",
    "#As we see, the feature \"price\" is numerical, however the other are ordinal (not numerical)\n",
    "# In order to ensure the correct behaviour or certain ML algorithms we need to perform a mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purple</td>\n",
       "      <td>2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pink</td>\n",
       "      <td>3</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    color  size  price  model\n",
       "0  yellow     1   22.4      0\n",
       "1  purple     2   25.4      0\n",
       "2    pink     3   29.4      1"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since in this case the size means that one is begger than other, we do not transform it into dummy variable\n",
    "size_mapping = {'L':3, 'M':2, 'S':1}\n",
    "df['size'] = df['size'].map(size_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding: It is convinient to perform the same kind of mapping with non numeric labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model1': 0, 'model2': 1}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a similar approach to the obe followed before\n",
    "import numpy as np\n",
    "model_mapping = {label:idx for idx,label in enumerate (np.unique(df['model']))}\n",
    "model_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transofrm the class labels into ingerers:\n",
    "df['model'] = df['model'].map(model_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purple</td>\n",
       "      <td>2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pink</td>\n",
       "      <td>3</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    color  size  price  model\n",
       "0  yellow     1   22.4      0\n",
       "1  purple     2   25.4      0\n",
       "2    pink     3   29.4      1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: there is a \"labelEncoder\" class implemented in scikit learn that provides the same result:\n",
    "df = pd.DataFrame([['yellow','S',22.4, 'model1'],\n",
    "                  ['purple','M',25.4, 'model1'],\n",
    "                  ['pink','L',29.4, 'model2']],columns =['color','size','price','model'])\n",
    "df\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "model_le = LabelEncoder()\n",
    "y = model_le.fit_transform(df['model'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['model1', 'model1', 'model2'], dtype=object)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can recover the original text string for the label calc. the inverse\n",
    "model_le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW TRY:  with DUMMY FEATURES\n",
    "\n",
    "Unfortunately we cannot apply the same encoding for nominal features such as the color row. If we do so (assume yellow = 0, purple =1, pink=2), the learning algorithm will assume that PINK is larger than yellow and purple.\n",
    "\n",
    "So, we need to use a techinque called \"one-hot encoding\". This approach will create a new dummy feature for each unique value in the nominal feature column.\n",
    "\n",
    "We can use \"OneHotEncoder\" from the scikit-learn.preprocessing library, or even better, PANDAS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yellow</td>\n",
       "      <td>S</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purple</td>\n",
       "      <td>M</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pink</td>\n",
       "      <td>L</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    color size  price  model\n",
       "0  yellow    S   22.4      0\n",
       "1  purple    M   25.4      0\n",
       "2    pink    L   29.4      1"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we define the column position that we want to transform\n",
    "df = pd.DataFrame([['yellow','S',22.4, 'model1'],\n",
    "                  ['purple','M',25.4, 'model1'],\n",
    "                  ['pink','L',29.4, 'model2']],columns =['color','size','price','model'])\n",
    "\n",
    "# first we transform the label, same as before\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "model_le = LabelEncoder()\n",
    "y = model_le.fit_transform(df['model'].values)\n",
    "df['model'] = y\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purple</td>\n",
       "      <td>2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pink</td>\n",
       "      <td>3</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    color  size  price  model\n",
       "0  yellow     1   22.4      0\n",
       "1  purple     2   25.4      0\n",
       "2    pink     3   29.4      1"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform mapping for nominal feature that has certain order, S < M < L. \n",
    "# For other use dummy variables\n",
    "size_mapping = {'L':3, 'M':2, 'S':1}\n",
    "df['size'] = df['size'].map(size_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>model</th>\n",
       "      <th>color_pink</th>\n",
       "      <th>color_purple</th>\n",
       "      <th>color_yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size  price  model  color_pink  color_purple  color_yellow\n",
       "0     1   22.4      0           0             0             1\n",
       "1     2   25.4      0           0             1             0\n",
       "2     3   29.4      1           1             0             0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PANDAS approach\n",
    "\n",
    "# now we transform the remaning features (strings) to be transformed into dummy variables\n",
    "pd.get_dummies(df[['size','color','price','model']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',\n",
    "                      header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wine.columns= ['Class label', 'Alcohol',\n",
    "                 'Malic acid', 'Ash',\n",
    "                 'Alcalinity of ash',' Magnesium',\n",
    "                 'Total phenols', 'Flavanoids', \n",
    "                 'Nonflavanoid phenols',\n",
    "                 'Proanthocyasnins',\n",
    "                 'Color intensity', 'Hue',\n",
    "                 'OD280/OD315 of diluted wines',\n",
    "                 'Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyasnins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash   Magnesium  \\\n",
       "0            1    14.23        1.71  2.43               15.6         127   \n",
       "1            1    13.20        1.78  2.14               11.2         100   \n",
       "2            1    13.16        2.36  2.67               18.6         101   \n",
       "3            1    14.37        1.95  2.50               16.8         113   \n",
       "4            1    13.24        2.59  2.87               21.0         118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyasnins  \\\n",
       "0           2.80        3.06                  0.28              2.29   \n",
       "1           2.65        2.76                  0.26              1.28   \n",
       "2           2.80        3.24                  0.30              2.81   \n",
       "3           3.85        3.49                  0.24              2.18   \n",
       "4           2.80        2.69                  0.39              1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels:  [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Exploring data:  differnet class labels\n",
    "print 'Class labels: ',np.unique(df_wine['Class label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition dataset into training and test\n",
    "### using cross_validation library, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#first , seprate label and features\n",
    "X,y = df_wine.iloc[:,1:].values, df_wine.iloc[:,0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.42300000e+01,   1.71000000e+00,   2.43000000e+00, ...,\n",
       "          1.04000000e+00,   3.92000000e+00,   1.06500000e+03],\n",
       "       [  1.32000000e+01,   1.78000000e+00,   2.14000000e+00, ...,\n",
       "          1.05000000e+00,   3.40000000e+00,   1.05000000e+03],\n",
       "       [  1.31600000e+01,   2.36000000e+00,   2.67000000e+00, ...,\n",
       "          1.03000000e+00,   3.17000000e+00,   1.18500000e+03],\n",
       "       ..., \n",
       "       [  1.32700000e+01,   4.28000000e+00,   2.26000000e+00, ...,\n",
       "          5.90000000e-01,   1.56000000e+00,   8.35000000e+02],\n",
       "       [  1.31700000e+01,   2.59000000e+00,   2.37000000e+00, ...,\n",
       "          6.00000000e-01,   1.62000000e+00,   8.40000000e+02],\n",
       "       [  1.41300000e+01,   4.10000000e+00,   2.74000000e+00, ...,\n",
       "          6.10000000e-01,   1.60000000e+00,   5.60000000e+02]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming features onto the same scale\n",
    "### Two common methods to bring different features to the same scale: \n",
    "- ### Normalization\n",
    " \n",
    " Features between [0,1]\n",
    " \n",
    " Normalization via min-max scaling commonly used, values bounded interval, standarization can be more practical for many ML algorithms.\n",
    "\n",
    "   X_norm_(i) = X(i) - X(min) / X(max) - X(min)\n",
    "   \n",
    "- ### Standarization\n",
    "\n",
    "    Feature columns centered at mean 0 with standard deviation 1, so columns take the form of  a normal distribution. It maintains useful information about outliers and makes the algorithm lesss sensitive to them in contrast to min-max scaling\n",
    "  \n",
    "  X_std_(i)= X(i) - U (mean) / STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.203782</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.543165</td>\n",
       "      <td>0.737003</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.401899</td>\n",
       "      <td>0.240688</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319892</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>0.311828</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.453237</td>\n",
       "      <td>0.480122</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.525316</td>\n",
       "      <td>0.135626</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.712185</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.176259</td>\n",
       "      <td>0.067278</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.294304</td>\n",
       "      <td>0.851958</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.423482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.563025</td>\n",
       "      <td>0.424731</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.143885</td>\n",
       "      <td>0.024465</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.259790</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.150183</td>\n",
       "      <td>0.419433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760753</td>\n",
       "      <td>0.130252</td>\n",
       "      <td>0.704301</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.665468</td>\n",
       "      <td>0.730887</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.458861</td>\n",
       "      <td>0.200573</td>\n",
       "      <td>0.700855</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.079352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.720430  0.203782  0.537634  0.309278  0.336957  0.543165  0.737003   \n",
       "1  0.319892  0.084034  0.311828  0.432990  0.239130  0.453237  0.480122   \n",
       "2  0.602151  0.712185  0.483871  0.484536  0.543478  0.176259  0.067278   \n",
       "3  0.572581  0.563025  0.424731  0.536082  0.347826  0.143885  0.024465   \n",
       "4  0.760753  0.130252  0.704301  0.742268  0.173913  0.665468  0.730887   \n",
       "\n",
       "         7         8         9         10        11        12  \n",
       "0  0.250000  0.401899  0.240688  0.487179  1.000000  0.585425  \n",
       "1  0.480769  0.525316  0.135626  0.273504  0.641026  0.000000  \n",
       "2  0.557692  0.294304  0.851958  0.042735  0.106227  0.423482  \n",
       "3  0.557692  0.278481  0.259790  0.051282  0.150183  0.419433  \n",
       "4  0.134615  0.458861  0.200573  0.700855  0.692308  0.079352  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)\n",
    "\n",
    "#The output are numpy arrays. LEt's transform it to DataFrames (pandas) and explore them\n",
    "pd.DataFrame(X_train_norm).head()\n",
    "\n",
    "\n",
    "# as we see the values are normalized between [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.910831</td>\n",
       "      <td>-0.462599</td>\n",
       "      <td>-0.011426</td>\n",
       "      <td>-0.820679</td>\n",
       "      <td>0.062417</td>\n",
       "      <td>0.588204</td>\n",
       "      <td>0.935654</td>\n",
       "      <td>-0.761914</td>\n",
       "      <td>0.130072</td>\n",
       "      <td>-0.512387</td>\n",
       "      <td>0.657066</td>\n",
       "      <td>1.943545</td>\n",
       "      <td>0.937010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.956099</td>\n",
       "      <td>-0.966087</td>\n",
       "      <td>-1.537254</td>\n",
       "      <td>-0.147487</td>\n",
       "      <td>-0.554019</td>\n",
       "      <td>0.169986</td>\n",
       "      <td>0.072432</td>\n",
       "      <td>0.207913</td>\n",
       "      <td>0.784626</td>\n",
       "      <td>-0.982107</td>\n",
       "      <td>-0.408595</td>\n",
       "      <td>0.581180</td>\n",
       "      <td>-1.413367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.359522</td>\n",
       "      <td>1.675016</td>\n",
       "      <td>-0.374718</td>\n",
       "      <td>0.133010</td>\n",
       "      <td>1.363782</td>\n",
       "      <td>-1.118128</td>\n",
       "      <td>-1.314889</td>\n",
       "      <td>0.531189</td>\n",
       "      <td>-0.440566</td>\n",
       "      <td>2.220529</td>\n",
       "      <td>-1.559509</td>\n",
       "      <td>-1.448466</td>\n",
       "      <td>0.286837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221695</td>\n",
       "      <td>1.047864</td>\n",
       "      <td>-0.774340</td>\n",
       "      <td>0.413506</td>\n",
       "      <td>0.130910</td>\n",
       "      <td>-1.268687</td>\n",
       "      <td>-1.458759</td>\n",
       "      <td>0.531189</td>\n",
       "      <td>-0.524483</td>\n",
       "      <td>-0.426984</td>\n",
       "      <td>-1.516883</td>\n",
       "      <td>-1.281645</td>\n",
       "      <td>0.270582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.098777</td>\n",
       "      <td>-0.771758</td>\n",
       "      <td>1.114780</td>\n",
       "      <td>1.535493</td>\n",
       "      <td>-0.964977</td>\n",
       "      <td>1.156982</td>\n",
       "      <td>0.915101</td>\n",
       "      <td>-1.246827</td>\n",
       "      <td>0.432174</td>\n",
       "      <td>-0.691735</td>\n",
       "      <td>1.722727</td>\n",
       "      <td>0.775804</td>\n",
       "      <td>-1.094782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.910831 -0.462599 -0.011426 -0.820679  0.062417  0.588204  0.935654   \n",
       "1 -0.956099 -0.966087 -1.537254 -0.147487 -0.554019  0.169986  0.072432   \n",
       "2  0.359522  1.675016 -0.374718  0.133010  1.363782 -1.118128 -1.314889   \n",
       "3  0.221695  1.047864 -0.774340  0.413506  0.130910 -1.268687 -1.458759   \n",
       "4  1.098777 -0.771758  1.114780  1.535493 -0.964977  1.156982  0.915101   \n",
       "\n",
       "         7         8         9         10        11        12  \n",
       "0 -0.761914  0.130072 -0.512387  0.657066  1.943545  0.937010  \n",
       "1  0.207913  0.784626 -0.982107 -0.408595  0.581180 -1.413367  \n",
       "2  0.531189 -0.440566  2.220529 -1.559509 -1.448466  0.286837  \n",
       "3  0.531189 -0.524483 -0.426984 -1.516883 -1.281645  0.270582  \n",
       "4 -1.246827  0.432174 -0.691735  1.722727  0.775804 -1.094782  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "#The output are numpy arrays. LEt's transform it to DataFrames (pandas) and explore them\n",
    "pd.DataFrame(X_train_std).head()\n",
    "\n",
    "# as we see the values are standarized , the mean is at 0 and STD = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization : regularization and diminsionality reduction\n",
    "zero out irrelevant features (L1)\n",
    "\n",
    "### Regularization with L1:\n",
    "L1 regularization obtains sparse feature vectors. Most feature weights will be zero. So weights vectos are SPARSE (a few non-zero entries). Useful as dimensionality reduction.\n",
    "\n",
    "### Regularization with L2: \n",
    "One approach to reduce the complexity of a model by penalizing large indicidual weights.\n",
    "It replaces the square of the weights by the sum of the absolute values of the weigths. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.983870967742\n",
      "Test accuracy:  0.981481481481\n",
      "Intercept: [-0.38378766 -0.15811471 -0.70038748]\n",
      "Weight - scope:  [[ 0.28029291  0.          0.         -0.02805272  0.          0.\n",
      "   0.71007683  0.          0.          0.          0.          0.\n",
      "   1.23591472]\n",
      " [-0.64384698 -0.06886261 -0.05718511  0.          0.          0.          0.\n",
      "   0.          0.         -0.92703131  0.05994892  0.         -0.3710137 ]\n",
      " [ 0.          0.06140729  0.          0.          0.          0.\n",
      "  -0.63726805  0.          0.          0.49852684 -0.35811144 -0.57011968\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# L1 regularized logistic regression \n",
    "#http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_l1_l2_sparsity.html\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print 'Training accuracy: ',lr.score(X_train_std, y_train)\n",
    "print 'Test accuracy: ',lr.score(X_test_std, y_test)\n",
    "#test and train accuracy does not indicate any overfitting\n",
    "\n",
    "print 'Intercept:',lr.intercept_\n",
    "# Multiclass dataset: it uses One-vs-Rest approach. First intercept class 1 versus 2 and 3.\n",
    "# Second inteircept class 2 versus 1 and 3\n",
    "# Third intercept class 3 versus 1 and 2\n",
    "print 'Weight - scope: ',lr.coef_\n",
    "# Each row has 13 weights where each weight is multipled by the respective feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Note that the weight vectors are sparse. It means that they only have a few non-zero entries. \n",
    "\n",
    "+ #### As a result of L1 regularization, which serves as method for FEATURE SELECTION, the model is trained to potentially irrelevant features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) FEATURE SELECTION: \n",
    "\n",
    "## Sequential feature selection algorithms:\n",
    "\n",
    "Alternative way to reduce complexity of models and avoid overfitting: dimensionality reduction via FEATURE SELECTION. Useful for unregularized models or algorithms that do not support regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWO MAIN TECHNIQUES OF DIMENSIONALITY REDUCTION \n",
    "+ #### Feature selection\n",
    "    Here it is selected a subset of the original features.\n",
    "+ #### Feature extraction\n",
    "    Here it is obtained information from the feature set to construct a new feature subspace.\n",
    "    \n",
    "    Aim : compress a dataset onto a lower dimiensional feature subspace.\n",
    "    \n",
    "    \n",
    "    \n",
    "Sequential feature selection algorithms are a kind of greed search algorithms that are used to reduce an initial d-diminsional feature space to a k-dimiensional feature subspace where k<d\n",
    "\n",
    "AIM feature selection algorithms: \n",
    "+ select a subset of features that are most relevant to the problem to improve computational efficiency\n",
    "+ Reduce the generalization error of the model by removing irrelevant features or noise. Useful for algorithms that do not support regulrization\n",
    "\n",
    "\n",
    "##### A sequential feature algorithm: SEQUENTIAL BACKWARD SELECTION (SBS)\n",
    "\n",
    "+ Aims to reduce dimensionality of the initial feature subspace with a minumum decay in performance of the classifier to improve upon computational efficientcy.\n",
    "+ Under certain condition, SBS can even improve the predictive power fot he model if it suffers from overfitting.\n",
    "    \n",
    "+ HOW IT WORKS: \n",
    "        It's pretty simple. The algorithm start removing features from the features subset until the new feature subspace contains the desired number of features. In order to decide which features to remove, in each step it will remove the feature that causes the least performance lost after removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining FEATURE importance using RANDOM FORESTS\n",
    "\n",
    "Above we used L1 regularization to zero out irrelevant features via Logistic Regression and use the SBS algorithm for feature selection. \n",
    "\n",
    "Another approach to select the most relevant features is using RANDOM FORESTS. A Random forest ensables a bunch of decission trees (note that non of these require normalization/standarization: same scale). The output of random forests collects the importance of each feature.\n",
    "\n",
    "Furthermore random forests provides us with an extra hint. If there is a feature hightly correlated with other/s , these will not show up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction: compreessing Data via Dimensionality Reduction\n",
    "\n",
    "Summarize the information content of a dataset by transforming it onto\n",
    "a new deature dubspace of lower dimensionality than the orifinal one.\n",
    "\n",
    "Data comporession is an important topic in ML. Store and analyze inceeasin amounts of data.\n",
    "+ Principal component analysis (PCA)\n",
    "    For unsupervised data compression\n",
    "+ Linear Discriminant Analysis (LDA)\n",
    "    As a supervised dimensionality reduction for maximizing class separability\n",
    "+ Non-linear dimensionality reduction via KERNEL PRINCIPAL ANALYSIS\n",
    "\n",
    "\n",
    "While we mantained the original features in FEATURE SELECTION ALGORITHMS (sequential backwared selection), in FEATURE EXTRACTION we transform or porject the data onto a new feature space.\n",
    "Defined as an approach to data compression with the goal of mantaining most of the relevant information.\n",
    "+ Used to improve computational efficiency\n",
    "+ Bug can also help to reduce the dimensionality, especially in nonregularized models. \n",
    "\n",
    "\n",
    "\n",
    "+ ### PCA:\n",
    "Sensitive to data scale. We need to standarize the feeatures prior to PCA in oder to assign equal importance to all features. \n",
    "\n",
    " 1. Standarize the d-dimensional dataset\n",
    " 2. Construct the covarnance matrix.\n",
    " 3. Decomprose the covariance matrix into its eigenvectors and eigenvalues.\n",
    " 4. Select k eigenvectors that correspond to the k larges eigenvalues , where k is the dimensionality of the new featuure subspace (k<= d)\n",
    " 5. Construc a projection matrix W from the \"top\" k eigenvectors.\n",
    " 6. Transform the d-dimensional input dataset X using the projection matrix W to obtain the new k-dimensional feature subspace.\n",
    " \n",
    " \n",
    " Projects data onto a lower-dimensional subspace to maximize the varianze along he orhogonal feature axes while ignoring the class labels.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy:  0.967741935484\n",
      "Test accuracy:  0.981481481481\n",
      "Intercept: [-1.627888  -1.0724269 -1.9969406]\n",
      "Weight - scope:  [[-1.59954057  1.44963046]\n",
      " [-0.06658775 -2.90262559]\n",
      " [ 1.51638726  1.57383394]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "lr = LogisticRegression()\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "lr.fit(X_train_pca,y_train)\n",
    "\n",
    "print 'Training accuracy: ',lr.score(X_train_pca, y_train)\n",
    "print 'Test accuracy: ',lr.score(X_test_pca, y_test)\n",
    "#test and train accuracy does not indicate any overfitting\n",
    "\n",
    "print 'Intercept:',lr.intercept_\n",
    "# Multiclass dataset: it uses One-vs-Rest approach. First intercept class 1 versus 2 and 3.\n",
    "# Second inteircept class 2 versus 1 and 3\n",
    "# Third intercept class 3 versus 1 and 2\n",
    "print 'Weight - scope: ',lr.coef_\n",
    "# Each row has 13 weights where each weight is multipled by the respective feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ### LDA:\n",
    "\n",
    "    In contrast to PCA, is a techinique for supervised dimensionality reduction. It considers class information in the training dataset to attempt to maximize the class-separability in a linear feature space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ### Kernel version of PCA:\n",
    "    \n",
    "    Allows to map nonlinear datasets onto a lower-dimensional deature space where the classes become linearly separable.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "### PIPELINE\n",
    "\n",
    "+ Split data into X= features, Y = target/label. Train & Test subsets\n",
    "+ Pipeline:\n",
    "    1. Scaling: Standarization/Nornalization\n",
    "    2. Dimensionality Reduction: PCA / others\n",
    "    3. Learning Algorithm\n",
    "    4. Predictive model. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
